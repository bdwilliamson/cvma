% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sl_fn.R
\name{optim_risk_sl_nloglik}
\alias{optim_risk_sl_nloglik}
\title{Cross-validated negative log-likelihood for computing super learner}
\usage{
optim_risk_sl_nloglik(sl_weight, input, sl_control, l = 0, u = 1,
  trim = 0.001)
}
\arguments{
\item{sl_weight}{A numeric vector of super learner weights corresponding to each
\code{learner}. Typically, this is what is maximized over in \code{sl_control$weight_fn}.}

\item{input}{A list where each entry corresponds to a validation fold. Each entry is a list
with entries: Y (univariate outcome for this validation fold), pred (matrix of predictions
from \code{learner} and columns correspond to different \code{leaner}s).}

\item{sl_control}{Super learner control options.}

\item{l}{Lower bound on outcomes}

\item{u}{Upper bound on outcomes}

\item{trim}{Where to trim \code{qlogis} to avoid \code{NA}s.}
}
\value{
Numeric value of cross-validated negative log-likelihood
}
\description{
In general, the function passed to \code{sl_control$optim_risk} should expect a named list
of outcomes (Y) and predictions (pred) in validation folds and should return a criteria by
which super learner weights may be optimized. The weights are input to the function via
\code{sl_weight} and are optimized in the \code{sl_control$weight_fn}. See
Examples section below for an example of the format of the \code{input} list used
for \code{sl_control$optim_risk} functions.
}
\details{
In this case, the function computes cross-validated (quasi-) log-likelihood for the outcomes
scaled to be between 0 and 1. The option \code{trim} must be a value greater than
zero in order that the loss is bounded. The bounds on the outcome are set via
\code{l} and \code{u}.
}
\examples{

}
