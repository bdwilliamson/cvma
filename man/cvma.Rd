% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cvma.R
\name{cvma}
\alias{cvma}
\title{Cross-validated maximal association measures}
\usage{
cvma(Y, X, V = 5, learners, sl_control = list(ensemble_fn =
  "ensemble_linear", optim_risk_fn = "optim_risk_sl_se", weight_fn =
  "weight_sl_convex", cv_risk_fn = "cv_risk_sl_r2", family = gaussian(), alpha =
  0.05), y_weight_control = list(ensemble_fn = "ensemble_linear", weight_fn =
  "weight_y_convex", optim_risk_fn = "optim_risk_y_r2", cv_risk_fn =
  "cv_risk_y_r2", alpha = 0.05), return_outer_weight = TRUE,
  return_outer_sl = TRUE, return_all_y = TRUE, return_all_learners = TRUE,
  scale = FALSE)
}
\arguments{
\item{Y}{A matrix or data.frame of outcomes}

\item{X}{A matrix or data.frame of predictors}

\item{V}{Number of outer folds of cross-validation (nested cross-validation
uses V-1 and V-2 folds), so must be at least four.}

\item{learners}{Super learner wrappers. See \code{SuperLearner::listWrappers}.}

\item{sl_control}{A list with named entries ensemble_fn, optim_risk_fn, weight_fn,
cv_risk_fn, family. Available functions can be viewed with \code{sl_control_options()}. See
\code{?sl_control_options} for more on how users may supply their own functions.}

\item{y_weight_control}{A list with named entries ensemble_fn, optim_risk_fn, weight_fn,
cv_risk_fn. Available functions can be viewed with \code{y_weight_control_options()}. See
\code{?y_weight_control_options} for more on how users may supply their own functions.}

\item{return_outer_weight}{Whether to return estimate of outcome
weights the outer most cross-validation layer (i.e, based on V - 1 cross-validated 
super learner risks).}

\item{return_outer_sl}{Whether to return the super learner for the outer most cross-validation
layer (i.e., V-fold super learner).}

\item{return_all_y}{Whether to return cross-validated performance measures for each
column of \code{Y}.}

\item{return_all_learners}{Whether to return cross-validated performance measures for 
each learner.}

\item{scale}{Standardize each outcome to be mean zero with standard deviation 1.}
}
\value{
If \code{return_outer_sl} is TRUE, it will return for each outcome Super Learner fit weights 
and associated risk for each learner. In addition, it will return the fit for all learners based on 
all folds. If \code{return_outer_weight} is TRUE, it will return the weights for each outcome
obtained using V-1 cross-validation. If \code{return_all_y} is TRUE, it will return for each 
outcome cross-validated measure (nonparametric R-squared or AUC), confidence interval and associated
p-value.
}
\description{
A flexible interface for computing cross-validation-based measures of maximal association.
In an outer layer of V-fold cross validation, training samples are used to train a prediction 
algorithm for each outcome. Multiple algorithms may be ensembled using stacking (also known as 
super learning) based on V-2 fold cross-validation. An inner layer of V-1 cross validation is used 
to determine a user-specified combination of outcomes that maximizes a user-specified prediction 
criteria. The outer layer
validation sample is used to compute a user-specified cross-validated measure of performance of
the prediction algorithm for predicting the combined outcome that was computed in the training 
sample. Several common choices for outcome combinations (convex combination of
outcomes and single outcome that is most associated) and prediction criteria (nonparametric R^2,
negative log-likelihood, and area under ROC curve) are included; however, users may specify
their own criteria as well. The function returns the cross-validated summary measure for the
maximally combined outcome and, if desired, the cross-validated summary measure for each 
outcome.
}
\details{
TO DO: Figure out how future works (e.g., can plan() be specified internally
or externally?)
}
\examples{
set.seed(1234)
library(SuperLearner)
library(future)
X <- data.frame(x1=runif(n=100,0,5), x2=runif(n=100,0,5))
Y1 <- rnorm(100, X$x1 + X$x2, 1)
Y2 <- rnorm(100, X$x1 + X$x2, 3)
Y <- data.frame(Y1 = Y1, Y2 = Y2)
fit <- cvma(Y = Y, X = X, V = 5, 
                learners = c("SL.glm","SL.mean"))


}
\seealso{
predict method
}
